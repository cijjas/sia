{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_json = {\n",
    "    \"problem\": {\n",
    "        \"type\": \"mnist_digits\",\n",
    "        \"data\": \"../res/ej4/xor.txt\",\n",
    "        \"output\": \"output/ej4/xor.csv\"\n",
    "    },\n",
    "    \"network\": {\n",
    "        \"topology\": [\n",
    "            784,\n",
    "            30,\n",
    "            10\n",
    "        ],\n",
    "        \"activation_function\": {\n",
    "            \"method\": \"sigmoid\",\n",
    "            \"beta\": 1\n",
    "        },\n",
    "        \"optimizer\": {\n",
    "            \"method\": \"adam\",\n",
    "            \"beta_1\": 0.9,\n",
    "            \"beta_2\": 0.999,\n",
    "            \"epsilon\": 1e-8\n",
    "        }\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"seed\": 42,\n",
    "        \"epochs\": 20,\n",
    "        \"mini_batch_size\": 16,\n",
    "        \"learning_rate\": 0.5,\n",
    "        \"epsilon\": 0.01\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "def prepare_mnist_data():\n",
    "    \"\"\"\n",
    "    Prepares the MNIST dataset for training.\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28*28).astype('float32') / 255\n",
    "    x_test = x_test.reshape(-1, 28*28).astype('float32') / 255\n",
    "    y_train = np.eye(10)[y_train]\n",
    "    y_test = np.eye(10)[y_test]\n",
    "\n",
    "    training_data = [(x.reshape(784, 1), y.reshape(10, 1))\n",
    "                     for x, y in zip(x_train, y_train)]\n",
    "    test_data = [(x.reshape(784, 1), y.reshape(10, 1))\n",
    "                 for x, y in zip(x_test, y_test)]\n",
    "    return training_data, test_data\n",
    "\n",
    "training_data, test_data= prepare_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 980 / 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m      8\u001b[0m sigmoid_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_json(sigmoid_json)\n\u001b[1;32m     11\u001b[0m sigmoid_m \u001b[38;5;241m=\u001b[39m MultilayerPerceptron(\n\u001b[1;32m     12\u001b[0m     seed\u001b[38;5;241m=\u001b[39msigmoid_config\u001b[38;5;241m.\u001b[39mseed,\n\u001b[1;32m     13\u001b[0m     sizes\u001b[38;5;241m=\u001b[39msigmoid_config\u001b[38;5;241m.\u001b[39mtopology,\n\u001b[1;32m     14\u001b[0m     activation_function\u001b[38;5;241m=\u001b[39msigmoid_config\u001b[38;5;241m.\u001b[39mactivation_function,\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39msigmoid_config\u001b[38;5;241m.\u001b[39moptimizer,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[43msigmoid_m\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m           \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigmoid_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmini_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigmoid_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmini_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m           \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigmoid_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m           \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m           \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m sigmoid_m\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore/tryign.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(sigmoid_m)\n",
      "File \u001b[0;32m~/chris/sia/tp3/src/models/mlp/network_enhanced.py:40\u001b[0m, in \u001b[0;36mMultilayerPerceptron.fit\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data)\u001b[0m\n\u001b[1;32m     36\u001b[0m mini_batches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     37\u001b[0m     training_data[k:k \u001b[38;5;241m+\u001b[39m mini_batch_size]\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n, mini_batch_size)]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mini_batch \u001b[38;5;129;01min\u001b[39;00m mini_batches:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_mini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_data:\n\u001b[1;32m     42\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n",
      "File \u001b[0;32m~/chris/sia/tp3/src/models/mlp/network_enhanced.py:57\u001b[0m, in \u001b[0;36mMultilayerPerceptron.update_mini_batch\u001b[0;34m(self, mini_batch, eta)\u001b[0m\n\u001b[1;32m     55\u001b[0m nabla_w \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(w\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m mini_batch:\n\u001b[0;32m---> 57\u001b[0m     delta_nabla_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     nabla_w \u001b[38;5;241m=\u001b[39m [nw \u001b[38;5;241m+\u001b[39m dnw \u001b[38;5;28;01mfor\u001b[39;00m nw, dnw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nabla_w, delta_nabla_w)]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Update weights using the optimizer\u001b[39;00m\n",
      "File \u001b[0;32m~/chris/sia/tp3/src/models/mlp/network_enhanced.py:71\u001b[0m, in \u001b[0;36mMultilayerPerceptron.backprop\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights:\n\u001b[1;32m     70\u001b[0m     a_aug \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([activation, [[\u001b[38;5;241m1\u001b[39m]]])  \u001b[38;5;66;03m# Append 1 for bias\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_aug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     zs\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m     73\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma\u001b[38;5;241m.\u001b[39mactivation(z)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.mlp.network_enhanced import MultilayerPerceptron\n",
    "from utils.config import Config\n",
    "\n",
    "\n",
    "models = []\n",
    "config = Config()\n",
    "\n",
    "sigmoid_config = config.get_json(sigmoid_json)\n",
    "\n",
    "\n",
    "sigmoid_m = MultilayerPerceptron(\n",
    "    seed=sigmoid_config.seed,\n",
    "    sizes=sigmoid_config.topology,\n",
    "    activation_function=sigmoid_config.activation_function,\n",
    "    optimizer=sigmoid_config.optimizer,\n",
    ")\n",
    "\n",
    "sigmoid_m.fit(training_data, \n",
    "           epochs=sigmoid_config.epochs, \n",
    "           mini_batch_size=sigmoid_config.mini_batch_size, \n",
    "           eta=sigmoid_config.learning_rate,\n",
    "           test_data=test_data\n",
    "           )\n",
    "\n",
    "sigmoid_m.save_model(\"store/tryign.npz\")\n",
    "\n",
    "models.append(sigmoid_m)\n",
    "\n",
    "model_copy = models.copy()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
