{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para correr esto es importante tener bien configurado el archivo hyperparameters, los análisis son en su mayoría sobre el perceptron descripto ahí. \n",
    "\n",
    "ej:\n",
    "\n",
    "# ej2_analysis.json\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"epochs\": 10000,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epsilon\": 1e-5,\n",
    "    \"non_linear_fn\": \"tanh\",\n",
    "    \"beta\": 2.0,\n",
    "    \"seed\": 42\n",
    "}\n",
    "```\n",
    "\n",
    "- Para ver el ultimo grafico usar sigmoid con algún beta menor a 1 y 1000 o más iteraciones\n",
    "- Para todo lo demás usar tanh 2.0 con n epochs\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"epochs\": 1000,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epsilon\": 1e-5,\n",
    "    \"non_linear_fn\": \"sigmoid\",\n",
    "    \"beta\": 0.5,\n",
    "    \"seed\": 42\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "from models.perceptrons.perceptron_linear import PerceptronLinear\n",
    "from models.perceptrons.perceptron_non_linear import PerceptronNonLinear\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leer y guardar x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = \"../config/ej2_analysis.json\"\n",
    "with open(config_file_path, 'r') as file:\n",
    "    config_file = json.load(file)\n",
    "    \n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../res/TP3-ej2-conjunto.csv\")\n",
    "\n",
    "print(\"Read dataset\")\n",
    "\n",
    "# Split the DataFrame into X and y\n",
    "X = df[['x1', 'x2', 'x3']].values\n",
    "y = df['y'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el non-linear hay que normalizar los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale inputs for sigmoid (0 to 1)\n",
    "scaler_X_sigmoid = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled_logistic = scaler_X_sigmoid.fit_transform(X)  # scaled for sigmoid\n",
    "\n",
    "# Scale inputs for tanh (-1 to 1)\n",
    "scaler_X_tanh = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaled_tanh = scaler_X_tanh.fit_transform(X)  # scaled for tanh\n",
    "\n",
    "# Scale outputs for sigmoid (0 to 1)\n",
    "scaler_y_sigmoid = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled_logistic = scaler_y_sigmoid.fit_transform(y.reshape(-1, 1)).ravel()  # scaled for sigmoid\n",
    "\n",
    "# Scale outputs for tanh (-1 to 1)\n",
    "scaler_y_tanh = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_scaled_tanh = scaler_y_tanh.fit_transform(y.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Perceptrons\n",
    "learning_rate = config_file.get('learning_rate', 0.01)\n",
    "epsilon = config_file.get('epsilon', 1e-5)\n",
    "seed = config_file.get('seed', 0)\n",
    "non_linear_fn = config_file.get('non_linear_fn', 'sigmoid')\n",
    "beta = config_file.get('beta', 0.9)\n",
    "\n",
    "perceptron_linear = PerceptronLinear(\n",
    "    seed=config_file.get('seed', 0),\n",
    "    num_features=X.shape[1],\n",
    "    learning_rate=config_file.get('learning_rate', 0.01),\n",
    "    epsilon=config_file.get('epsilon', 1e-5),\n",
    ")\n",
    "\n",
    "perceptron_non_linear = PerceptronNonLinear(\n",
    "    seed=config_file.get('seed', 0),\n",
    "    num_features=X.shape[1],\n",
    "    learning_rate=config_file.get('learning_rate', 0.01),\n",
    "    epsilon=config_file.get('epsilon', 1e-5),\n",
    "    non_linear_fn=config_file.get('non_linear_fn', 'sigmoid'),\n",
    "    beta=config_file.get('beta', 0.9)\n",
    ")\n",
    "\n",
    "\n",
    "# Train Perceptrons\n",
    "num_epochs =  config_file.get('epochs', 1000)\n",
    "X_scaled_c = X_scaled_logistic if non_linear_fn == 'sigmoid' else X_scaled_tanh\n",
    "y_scaled_c = y_scaled_logistic if non_linear_fn == 'sigmoid' else y_scaled_tanh\n",
    "scaler_X_c = scaler_X_sigmoid if non_linear_fn == 'sigmoid' else scaler_X_tanh\n",
    "scaler_y_c = scaler_y_sigmoid if non_linear_fn == 'sigmoid' else scaler_y_tanh\n",
    "\n",
    "perceptron_linear.train(X_scaled_c, y_scaled_c, num_epochs)\n",
    "# estoy metiendo el y normalizado en el perceptron non linear\n",
    "perceptron_non_linear.train(X_scaled_c, y_scaled_c, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular la diferencia de pérdida entre los dos modelos\n",
    "loss_difference = [linear - non_linear for linear, non_linear in zip(perceptron_linear.loss_history, perceptron_non_linear.loss_history)]\n",
    "\n",
    "# Graficar el historial de pérdidas de ambos modelos\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(perceptron_linear.loss_history, label='Linear Perceptron')\n",
    "plt.plot(perceptron_non_linear.loss_history, label='Non-linear Perceptron')\n",
    "\n",
    "loss_string =(\n",
    "  f'Loss history' + '\\n'\n",
    "  + f'$\\\\eta$ = {learning_rate}, seed = {seed}, non-linear function = {non_linear_fn}, $\\\\beta$ = {beta}'\n",
    ")\n",
    "plt.title(loss_string)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Graficar la diferencia de pérdidas\n",
    "plt.figure()\n",
    "plt.plot(loss_difference, label='Difference (Linear - Non-linear)')\n",
    "plt.title('Difference in Loss between Linear and Non-linear Perceptrons')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Difference')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weights history for Linear Perceptron\n",
    "plt.figure()\n",
    "weights_linear = np.array(perceptron_linear.weights_history)\n",
    "for i in range(weights_linear.shape[1]):\n",
    "    plt.plot(weights_linear[:, i], label=f'Weight {i}')\n",
    "wl_string =(\n",
    "  f'Weights History - Linear Perceptron' + '\\n'\n",
    "  + f'$\\\\eta$ = {learning_rate}, seed = {seed}'\n",
    ")\n",
    "plt.title(wl_string)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Weight Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Plot weights history for Non-linear Perceptron\n",
    "plt.figure()\n",
    "weights_non_linear = np.array(perceptron_non_linear.weights_history)\n",
    "for i in range(weights_non_linear.shape[1]):\n",
    "    plt.plot(weights_non_linear[:, i], label=f'Weight {i}')\n",
    "\n",
    "wnl_string =(\n",
    "  f'Weights History - Non-Linear Perceptron' + '\\n'\n",
    "  + f'$\\\\eta$ = {learning_rate}, seed = {seed}, non-linear function = {non_linear_fn}, $\\\\beta$ = {beta}'\n",
    ")\n",
    "plt.title(wnl_string)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Weight Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(y)\n",
    "\n",
    "\n",
    "# Evaluate predictions on training data\n",
    "y_pred_linear = perceptron_linear.predict(X_scaled_c)\n",
    "\n",
    "# Predict on the training data (for non-linear)\n",
    "y_pred_non_linear= perceptron_non_linear.predict(X_scaled_c)\n",
    "\n",
    "y_ss = y_scaled_c[sorted_indices]\n",
    "y_pred_linear_ss = y_pred_linear[sorted_indices]\n",
    "y_pred_non_linear_ss = y_pred_non_linear[sorted_indices]\n",
    "\n",
    "# Plot actual vs predicted outputs\n",
    "plt.figure()\n",
    "plt.plot(y_ss, 'o', label=r'$y$ Actual Output')\n",
    "plt.plot(y_pred_linear_ss, 'x', label=r'$O^{\\mu}_h$: Linear Perceptron Prediction')\n",
    "plt.plot(y_pred_non_linear_ss, '*', label=r'$O^{\\mu}_h$ Non-linear Perceptron Prediction')\n",
    "avtr_string =(\n",
    "  f'Actual vs Trained outputs after {num_epochs} epochs' + '\\n'\n",
    "  + f'$\\\\eta$ = {learning_rate}, seed = {seed}, non-linear function = {non_linear_fn}, $\\\\beta$ = {beta}'\n",
    ")\n",
    "plt.title(avtr_string)\n",
    "plt.xlabel('Sorted Sample Index')\n",
    "plt.ylabel(r'Output Value ')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#change this to show the actual ouptuts ordered from lowest to highest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J9470C624EPBFKXBN68KY8C5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Function to plot scatter and perceptron predictions with other features held at their mean\n",
    "def plot_perceptron_feature(ax, x, y, xlabel, perceptron_model, num_features, X_full):\n",
    "    # Scatter the actual data points\n",
    "    ax.scatter(x, y, c=y, cmap='viridis', label='True Values')\n",
    "    \n",
    "    # Create a copy of the dataset and set the other features to their average values\n",
    "    X_full_copy = np.mean(X_full, axis=0).reshape(1, -1)  # Start with the mean of all features\n",
    "    X_full_copy = np.tile(X_full_copy, (x.shape[0], 1))   # Tile to the size of the input\n",
    "    \n",
    "    # Identify the column corresponding to the feature being plotted\n",
    "    feature_index = int(xlabel[-1]) - 1\n",
    "    X_full_copy[:, feature_index] = x  # Replace only the current feature with its varying values\n",
    "\n",
    "    # Predict using the perceptron\n",
    "    y_pred = perceptron_model.predict(X_full_copy)\n",
    "\n",
    "    # Plot the model's predictions as a line\n",
    "    sorted_x = np.sort(x)\n",
    "    sorted_indices_x = np.argsort(x)\n",
    "    y_pred_sorted = y_pred[sorted_indices_x]\n",
    "    ax.plot(sorted_x, y_pred_sorted, color='red', linewidth=2, label='Perceptron Prediction')\n",
    "\n",
    "    # Calculate R2 score\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('y')\n",
    "    title= (f'{xlabel} vs y\\n$MSE$: {mse:.2f}' + '\\n'\n",
    "            + f'$\\\\eta$ = {learning_rate}, seed = {seed}')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "# Create a figure for plotting\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Assuming df['x1'], df['x2'], df['x3'] are your features, and y is the target variable\n",
    "# Pass the number of features your model was trained on (e.g., 3 if 3 features were used)\n",
    "num_features = X.shape[1]\n",
    "\n",
    "x1_scaled = X_scaled_c[:, 0]\n",
    "x2_scaled = X_scaled_c[:, 1]\n",
    "x3_scaled = X_scaled_c[:, 2]\n",
    "\n",
    "# Plot x1 vs y using PerceptronLinear with other features held at their mean values\n",
    "plot_perceptron_feature(axes[0], x1_scaled, y_scaled_c, 'x1', perceptron_linear, num_features, X_scaled_c)\n",
    "\n",
    "# Plot x2 vs y using PerceptronLinear with other features held at their mean values\n",
    "plot_perceptron_feature(axes[1], x2_scaled, y_scaled_c, 'x2', perceptron_linear, num_features, X_scaled_c)\n",
    "\n",
    "# Plot x3 vs y using PerceptronLinear with other features held at their mean values\n",
    "plot_perceptron_feature(axes[2], x3_scaled, y_scaled_c, 'x3', perceptron_linear, num_features, X_scaled_c)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J9470C63MW2XZB2T1RC3JTDP",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(beta)\n",
    "# Function to plot scatter and perceptron predictions with other features held at their mean\n",
    "def plot_perceptron_feature(ax, x, y, xlabel, perceptron_model, num_features, X_full):\n",
    "    # Scatter the actual data points\n",
    "    ax.scatter(x, y, c=y, cmap='viridis', label='True Values')\n",
    "    \n",
    "    # Create a copy of the dataset and set the other features to their average values\n",
    "    X_full_copy = np.mean(X_full, axis=0).reshape(1, -1)  # Start with the mean of all features\n",
    "    X_full_copy = np.tile(X_full_copy, (x.shape[0], 1))   # Tile to the size of the input\n",
    "    \n",
    "    # Identify the column corresponding to the feature being plotted\n",
    "    feature_index = int(xlabel[-1]) - 1\n",
    "    X_full_copy[:, feature_index] = x  # Replace only the current feature with its varying values\n",
    "\n",
    "    # Predict using the perceptron\n",
    "    y_pred = perceptron_model.predict(X_full_copy)\n",
    "\n",
    "    # Plot the model's predictions as a line\n",
    "    sorted_x = np.sort(x)\n",
    "    sorted_indices_x = np.argsort(x)\n",
    "    y_pred_sorted = y_pred[sorted_indices_x]\n",
    "    ax.plot(sorted_x, y_pred_sorted, color='red', linewidth=2, label='Perceptron Prediction')\n",
    "\n",
    "    # Calculate R2 score\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('y')\n",
    "    title= (f'{xlabel} vs y\\n$R^2$: {mse:.2f}' + '\\n'\n",
    "            + f'$\\\\eta$ = {learning_rate}, seed = {seed},' + '\\n'\n",
    "            + f' non-linear function = {non_linear_fn}, $\\\\beta$ = {beta}')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "# Create a figure for plotting\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Assuming df['x1'], df['x2'], df['x3'] are your features, and y is the target variable\n",
    "# Pass the number of features your model was trained on (e.g., 3 if 3 features were used)\n",
    "num_features = X_scaled_c.shape[1]\n",
    "\n",
    "x1_scaled = X_scaled_c[:, 0]\n",
    "x2_scaled = X_scaled_c[:, 1]\n",
    "x3_scaled = X_scaled_c[:, 2]\n",
    "\n",
    "# Plot x1 vs y using PerceptronNonLinear with other features held at their mean values\n",
    "plot_perceptron_feature(axes[0], x1_scaled, y_scaled_c, 'x1', perceptron_non_linear, num_features, X_scaled_c)\n",
    "\n",
    "# Plot x2 vs y using PerceptronNonLinear with other features held at their mean values\n",
    "plot_perceptron_feature(axes[1], x2_scaled, y_scaled_c, 'x2', perceptron_non_linear, num_features, X_scaled_c)\n",
    "\n",
    "# Plot x3 vs y using PerceptronNonLinear with other features held at their mean values\n",
    "plot_perceptron_feature(axes[2], x3_scaled, y_scaled_c, 'x3', perceptron_non_linear, num_features, X_scaled_c)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J8XJV4VT2E70PJNYKEN7ZV8V",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate configurations\n",
    "activations = ['tanh', 'sigmoid', 'relu']\n",
    "betas = [0.1, 0.5, 0.9, 1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "perceptrons = []\n",
    "for act in activations:\n",
    "    if(act == 'relu'):\n",
    "        perceptron = PerceptronNonLinear(\n",
    "            seed=seed, \n",
    "            num_features=X.shape[1], \n",
    "            learning_rate=learning_rate,\n",
    "            epsilon=epsilon, \n",
    "            non_linear_fn=act\n",
    "        )\n",
    "        perceptrons.append(perceptron)\n",
    "    else:\n",
    "        for beta in betas:\n",
    "            perceptrons.append(\n",
    "                PerceptronNonLinear(\n",
    "                    seed=seed, \n",
    "                    num_features=X_scaled_c.shape[1] if act == 'sigmoid' else X_scaled_tanh.shape[1], \n",
    "                    learning_rate=learning_rate,\n",
    "                    epsilon=epsilon, \n",
    "                    non_linear_fn=act, \n",
    "                    beta=beta\n",
    "                )\n",
    "            )\n",
    "# Train all perceptrons\n",
    "# Train all perceptrons\n",
    "for i, perceptron in enumerate(perceptrons):\n",
    "    if perceptron.fn_name == 'sigmoid':\n",
    "        perceptron.train(X_scaled_logistic, y_scaled_c, num_epochs)\n",
    "    elif perceptron.fn_name == 'tanh':\n",
    "        perceptron.train(X_scaled_tanh, y_scaled_tanh, num_epochs)\n",
    "    else:\n",
    "        perceptron.train(X, y, num_epochs)\n",
    "\n",
    "perceptrons_copy = perceptrons.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01J8XS06GDS82YR9FB7J5N0AJJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scael tanh back to normal\n",
    "def inverse_scale_sigmoid(scaled_X):\n",
    "    return scaler_X_sigmoid.inverse_transform(scaled_X)\n",
    "\n",
    "def inverse_scale_tanh(scaled_X):\n",
    "    return scaler_X_tanh.inverse_transform(scaled_X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01J8Z86FY84FH06VYN5RV9VC8V",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perceptrons = perceptrons[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J8Z9B4YSB0F911E6GCDHY1GB",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # for a wider variety of colors\n",
    "\n",
    "def plot_perceptron_feature(ax, x, y, xlabel, perceptrons, num_features, X_full):\n",
    "    # Scatter the actual data points\n",
    "    ax.scatter(x, y, c=y, cmap='viridis', label='True Values')\n",
    "    \n",
    "    # Prepare colors\n",
    "    colors = sns.color_palette(\"hls\", len(perceptrons))\n",
    "\n",
    "    # Define labels based on your specifications\n",
    "    labels = ['tanh'] * 7 + ['logistic'] * 7 + ['relu'] \n",
    "\n",
    "    for idx, (perceptron_model, color) in enumerate(zip(perceptrons, colors)):\n",
    "        # Create a copy of the dataset and set the other features to their average values\n",
    "        X_full_copy = np.mean(X_full, axis=0).reshape(1, -1)\n",
    "        X_full_copy = np.tile(X_full_copy, (x.shape[0], 1))\n",
    "        \n",
    "        # Identify the column corresponding to the feature being plotted\n",
    "        feature_index = int(xlabel[-1]) - 1\n",
    "        X_full_copy[:, feature_index] = x\n",
    "        \n",
    "        # Apply the appropriate scaler depending on the perceptron type\n",
    "        \n",
    "        scaler = scaler_X_sigmoid if perceptron_model.fn_name == 'sigmoid'else scaler_X_tanh if perceptron_model.fn_name == 'tanh' else None\n",
    "\n",
    "        if scaler is not None:\n",
    "            X_full_copy = scaler.transform(X_full_copy)\n",
    "\n",
    "        # Predict using the perceptron\n",
    "        \n",
    "        y_pred = perceptron_model.predict(X_full_copy)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            y_pred = y_pred.reshape(-1, 1)\n",
    "            y_pred = scaler_y_sigmoid.inverse_transform(y_pred) if perceptron_model.fn_name == 'sigmoid' else scaler_y_tanh.inverse_transform(y_pred) \n",
    "            # Ensure y_pred is reshaped correctly for inverse_transform\n",
    "\n",
    "            # Apply inverse scaling to predictions\n",
    "\n",
    "            # Flatten the predictions back to 1D\n",
    "            y_pred = y_pred.flatten()\n",
    "\n",
    "        # Plot the model's predictions\n",
    "        sorted_x = np.sort(x)\n",
    "        sorted_indices_x = np.argsort(x)\n",
    "        y_pred = y_pred[sorted_indices_x]\n",
    "        add_beta = f' $\\\\beta$ = {perceptron_model.beta}' if perceptron_model.fn_name != 'relu' else ''\n",
    "        ax.plot(sorted_x, y_pred, color=color, linewidth=2, label=f'{labels[idx]}: {add_beta}')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title(f'{xlabel} vs y')\n",
    "    \n",
    "    # Place the legend outside the plot\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Create a figure for plotting\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Assuming df['x1'], df['x2'], df['x3'] are your features, and y is the target variable\n",
    "num_features = X.shape[1]\n",
    "\n",
    "x1 = X[:, 0]\n",
    "x2 = X[:, 1]\n",
    "x3 = X[:, 2]\n",
    "\n",
    "# Example list of trained perceptrons (replace with your actual list of perceptrons)\n",
    "\n",
    "# Plot for each feature\n",
    "plot_perceptron_feature(axes[0], x1, y, 'x1', perceptrons, num_features, X)\n",
    "plot_perceptron_feature(axes[1], x2, y, 'x2', perceptrons, num_features, X)\n",
    "plot_perceptron_feature(axes[2], x3, y, 'x3', perceptrons, num_features, X)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J946PHY8YP9FCW2QYD2WJ2F4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # for a wider variety of colors\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def plot_perceptron_feature(ax, x, y, xlabel, perceptrons, num_features, X_full, filter_fn=None):\n",
    "    # Scatter the actual data points\n",
    "    ax.scatter(x, y, c=y, cmap='viridis', label='True Values')\n",
    "    \n",
    "    # Prepare colors\n",
    "    colors = sns.color_palette(\"hls\", len(perceptrons))\n",
    "\n",
    "    # Define labels based on your specifications\n",
    "    labels = ['tanh'] * 7 + ['logistic'] * 7 + ['relu']\n",
    "\n",
    "    for idx, (perceptron_model, color) in enumerate(zip(perceptrons, colors)):\n",
    "        if filter_fn and not filter_fn(perceptron_model):\n",
    "            continue\n",
    "\n",
    "        # Create a copy of the dataset and set the other features to their average values\n",
    "        X_full_copy = np.mean(X_full, axis=0).reshape(1, -1)\n",
    "        X_full_copy = np.tile(X_full_copy, (x.shape[0], 1))\n",
    "        \n",
    "        # Identify the column corresponding to the feature being plotted\n",
    "        feature_index = int(xlabel[-1]) - 1\n",
    "        X_full_copy[:, feature_index] = x\n",
    "        \n",
    "        # Apply the appropriate scaler depending on the perceptron type\n",
    "        scaler = scaler_X_sigmoid if perceptron_model.fn_name == 'sigmoid' else scaler_X_tanh if perceptron_model.fn_name == 'tanh' else None\n",
    "\n",
    "        if scaler is not None:\n",
    "            X_full_copy = scaler.transform(X_full_copy)\n",
    "\n",
    "        # Predict using the perceptron\n",
    "        y_pred = perceptron_model.predict(X_full_copy)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            y_pred = y_pred.reshape(-1, 1)\n",
    "            y_pred = scaler_y_sigmoid.inverse_transform(y_pred) if perceptron_model.fn_name == 'sigmoid' else scaler_y_tanh.inverse_transform(y_pred) \n",
    "            y_pred = y_pred.flatten()\n",
    "\n",
    "        # Calculate R^2 score\n",
    "        r2 = r2_score(y, y_pred)\n",
    "\n",
    "        # Plot the model's predictions\n",
    "        sorted_x = np.sort(x)\n",
    "        sorted_indices_x = np.argsort(x)\n",
    "        y_pred = y_pred[sorted_indices_x]\n",
    "        \n",
    "        add_beta = f' $\\\\beta$ = {perceptron_model.beta}' if perceptron_model.fn_name != 'relu' else ''\n",
    "        ax.plot(sorted_x, y_pred, color=color, linewidth=2, label=f'{labels[idx]}: {add_beta}, $R^2$ = {r2:.2f}')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title(f'{xlabel} vs y')\n",
    "    \n",
    "    # Place the legend outside the plot\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Function to filter perceptrons based on the activation function\n",
    "def filter_sigmoid(perceptron_model):\n",
    "    return perceptron_model.fn_name == 'sigmoid'\n",
    "\n",
    "def filter_tanh_relu(perceptron_model):\n",
    "    return perceptron_model.fn_name in ['tanh', 'relu']\n",
    "\n",
    "# Create a figure for plotting tanh and relu\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot for tanh and relu models\n",
    "plot_perceptron_feature(axes[0], X[:, 0], y, 'x1', perceptrons, num_features, X, filter_fn=filter_tanh_relu)\n",
    "plot_perceptron_feature(axes[1], X[:, 1], y, 'x2', perceptrons, num_features, X, filter_fn=filter_tanh_relu)\n",
    "plot_perceptron_feature(axes[2], X[:, 2], y, 'x3', perceptrons, num_features, X, filter_fn=filter_tanh_relu)\n",
    "\n",
    "# Adjust layout and show the tanh and relu plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a second figure for plotting sigmoid\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot for sigmoid models\n",
    "plot_perceptron_feature(axes[0], X[:, 0], y, 'x1', perceptrons, num_features, X, filter_fn=filter_sigmoid)\n",
    "plot_perceptron_feature(axes[1], X[:, 1], y, 'x2', perceptrons, num_features, X, filter_fn=filter_sigmoid)\n",
    "plot_perceptron_feature(axes[2], X[:, 2], y, 'x3', perceptrons, num_features, X, filter_fn=filter_sigmoid)\n",
    "\n",
    "# Adjust layout and show the sigmoid plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envtp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
